{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TahaMsv/Bachelor-Project/blob/main/bachelor_project(SincNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fET9knZmqAnl",
        "outputId": "f2eefc30-e0eb-4d19-9e0b-277cec838e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvw6t_41r0Q6",
        "outputId": "cb62f87a-f92a-4274-bb2a-3e8c0ea516ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA4bSxOQ3QBY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLkCopVSlPzh"
      },
      "outputs": [],
      "source": [
        "# base_path = \"/drive/Shared with me/Bachelor's project/UC San Diego/\"\n",
        "base_path = \"/content/drive/MyDrive/Bachelor's project/UC San Diego/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np4mGZVKQrOw"
      },
      "source": [
        "#Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCSrt3wnGu4g"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "patient_raw = mne.io.read_raw_bdf(base_path + \"pd/Copy of sub-pd3_ses-off_task-rest_eeg.bdf\", preload=True)\n",
        "patient_raw.plot(\n",
        "    scalings='auto',\n",
        "    show=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meD49GZ-G9Ro"
      },
      "outputs": [],
      "source": [
        "normal_raw = mne.io.read_raw_bdf(base_path + \"hc/Copy of sub-hc1_ses-hc_task-rest_eeg.bdf\", preload=True)\n",
        "normal_raw.plot(\n",
        "    scalings='auto',\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JIkGFrjG3PM",
        "outputId": "d7978d4f-4b72-4d6c-c519-993fe76c7880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Channels: 41\n",
            "Sampling Rate: 512.0\n",
            "Channel Names: ['Fp1', 'AF3', 'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5', 'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8', 'CP6', 'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz', 'EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status']\n",
            "Recording Duration (seconds): 191.998046875\n"
          ]
        }
      ],
      "source": [
        "num_channels = normal_raw.info['nchan']\n",
        "sampling_rate = normal_raw.info['sfreq']\n",
        "channel_names = normal_raw.info['ch_names']\n",
        "recording_duration = normal_raw.times[-1]\n",
        "\n",
        "print(\"Number of Channels:\", num_channels)\n",
        "print(\"Sampling Rate:\", sampling_rate)\n",
        "print(\"Channel Names:\", channel_names)\n",
        "print(\"Recording Duration (seconds):\", recording_duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MBpTRO7HH0z"
      },
      "outputs": [],
      "source": [
        "data =np.load(base_path + \"pre processed data.npy\")\n",
        "labels = np.load(base_path + \"pre processed labels.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scT55lSX6UMa",
        "outputId": "bee76e57-2f2f-43a7-d659-d5de0a3e5b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2880, 41, 1024)\n",
            "(2880,)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tgqaiq1-Lm4"
      },
      "outputs": [],
      "source": [
        "# eeg_data_shape = data.shape\n",
        "# # Reshape the data into a 2D array with shape (2880, 41 * 1024)\n",
        "# data = data.reshape((eeg_data_shape[0],1, eeg_data_shape[1] * eeg_data_shape[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka7pUKRNQhEh"
      },
      "source": [
        "#Standard CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Slr6s3JfsEX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class PDCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PDCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=41, out_channels=5, kernel_size=20, stride=1)\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels=5, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=15, kernel_size=5, stride=1)\n",
        "        self.maxpool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=855, out_features=20)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=20, out_features=10)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(in_features=10, out_features=2)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool1(torch.relu(self.conv1(x)))\n",
        "        x = self.maxpool2(torch.relu(self.conv2(x)))\n",
        "        x = self.maxpool3(torch.relu(self.conv3(x)))\n",
        "        x = self.maxpool4(torch.relu(self.conv4(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
        "        x = self.dropout2(torch.relu(self.fc2(x)))\n",
        "        x = self.dropout3(self.fc3(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3XQLB5vgfVH",
        "outputId": "049e9de6-eb0d-4db4-d107-1ca478f67118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n",
            "Epoch [1/50], Loss: 0.6906191110610962\n",
            "Epoch [2/50], Loss: 0.7074005603790283\n",
            "Epoch [3/50], Loss: 0.679111897945404\n",
            "Epoch [4/50], Loss: 0.6800945997238159\n",
            "Epoch [5/50], Loss: 0.6980800628662109\n",
            "Epoch [6/50], Loss: 0.6749581694602966\n",
            "Epoch [7/50], Loss: 0.6808867454528809\n",
            "Epoch [8/50], Loss: 0.6927914023399353\n",
            "Epoch [9/50], Loss: 0.6987313628196716\n",
            "Epoch [10/50], Loss: 0.694846510887146\n",
            "Epoch [11/50], Loss: 0.7095680832862854\n",
            "Epoch [12/50], Loss: 0.6959211826324463\n",
            "Epoch [13/50], Loss: 0.6954081058502197\n",
            "Epoch [14/50], Loss: 0.6752502918243408\n",
            "Epoch [15/50], Loss: 0.695770263671875\n",
            "Epoch [16/50], Loss: 0.6922778487205505\n",
            "Epoch [17/50], Loss: 0.6966409087181091\n",
            "Epoch [18/50], Loss: 0.6972407102584839\n",
            "Epoch [19/50], Loss: 0.6843163371086121\n",
            "Epoch [20/50], Loss: 0.6840235590934753\n",
            "Epoch [21/50], Loss: 0.6713835000991821\n",
            "Epoch [22/50], Loss: 0.6520752310752869\n",
            "Epoch [23/50], Loss: 0.6389642953872681\n",
            "Epoch [24/50], Loss: 0.6253034472465515\n",
            "Epoch [25/50], Loss: 0.6097025275230408\n",
            "Epoch [26/50], Loss: 0.5803019404411316\n",
            "Epoch [27/50], Loss: 0.503726065158844\n",
            "Epoch [28/50], Loss: 0.5947094559669495\n",
            "Epoch [29/50], Loss: 0.46856892108917236\n",
            "Epoch [30/50], Loss: 0.5241032242774963\n",
            "Epoch [31/50], Loss: 0.46175262331962585\n",
            "Epoch [32/50], Loss: 0.3202306032180786\n",
            "Epoch [33/50], Loss: 0.4806075990200043\n",
            "Epoch [34/50], Loss: 0.4125785231590271\n",
            "Epoch [35/50], Loss: 0.2963990569114685\n",
            "Epoch [36/50], Loss: 0.32857370376586914\n",
            "Epoch [37/50], Loss: 0.37283870577812195\n",
            "Epoch [38/50], Loss: 0.39873629808425903\n",
            "Epoch [39/50], Loss: 0.35860884189605713\n",
            "Epoch [40/50], Loss: 0.365572988986969\n",
            "Epoch [41/50], Loss: 0.2910674214363098\n",
            "Epoch [42/50], Loss: 0.3225991129875183\n",
            "Epoch [43/50], Loss: 0.29620763659477234\n",
            "Epoch [44/50], Loss: 0.3550862967967987\n",
            "Epoch [45/50], Loss: 0.24398985505104065\n",
            "Epoch [46/50], Loss: 0.2562961280345917\n",
            "Epoch [47/50], Loss: 0.3209676146507263\n",
            "Epoch [48/50], Loss: 0.39086082577705383\n",
            "Epoch [49/50], Loss: 0.322712779045105\n",
            "Epoch [50/50], Loss: 0.2513183653354645\n",
            "Accuracy: 1.0, Specificity: 1.0, Sensitivity: 1.0\n",
            "\n",
            "Fold 2/10\n",
            "Epoch [1/50], Loss: 0.7103953957557678\n",
            "Epoch [2/50], Loss: 0.7245871424674988\n",
            "Epoch [3/50], Loss: 0.6818179488182068\n",
            "Epoch [4/50], Loss: 0.6933512687683105\n",
            "Epoch [5/50], Loss: 0.6950394511222839\n",
            "Epoch [6/50], Loss: 0.6852744817733765\n",
            "Epoch [7/50], Loss: 0.7050460577011108\n",
            "Epoch [8/50], Loss: 0.6780692934989929\n",
            "Epoch [9/50], Loss: 0.6968851089477539\n",
            "Epoch [10/50], Loss: 0.7099161744117737\n",
            "Epoch [11/50], Loss: 0.6958011388778687\n",
            "Epoch [12/50], Loss: 0.6889305114746094\n",
            "Epoch [13/50], Loss: 0.6901742219924927\n",
            "Epoch [14/50], Loss: 0.6961926817893982\n",
            "Epoch [15/50], Loss: 0.7026092410087585\n",
            "Epoch [16/50], Loss: 0.6950893402099609\n",
            "Epoch [17/50], Loss: 0.7038512825965881\n",
            "Epoch [18/50], Loss: 0.7085039615631104\n",
            "Epoch [19/50], Loss: 0.6984710693359375\n",
            "Epoch [20/50], Loss: 0.6870885491371155\n",
            "Epoch [21/50], Loss: 0.693738579750061\n",
            "Epoch [22/50], Loss: 0.6857448220252991\n",
            "Epoch [23/50], Loss: 0.6941365599632263\n",
            "Epoch [24/50], Loss: 0.6891252994537354\n",
            "Epoch [25/50], Loss: 0.6975264549255371\n",
            "Epoch [26/50], Loss: 0.6996142864227295\n",
            "Epoch [27/50], Loss: 0.6924930810928345\n",
            "Epoch [28/50], Loss: 0.6839057803153992\n",
            "Epoch [29/50], Loss: 0.691362738609314\n",
            "Epoch [30/50], Loss: 0.6893845796585083\n",
            "Epoch [31/50], Loss: 0.6862418055534363\n",
            "Epoch [32/50], Loss: 0.6905416250228882\n",
            "Epoch [33/50], Loss: 0.6939576864242554\n",
            "Epoch [34/50], Loss: 0.6890295743942261\n",
            "Epoch [35/50], Loss: 0.6930872201919556\n",
            "Epoch [36/50], Loss: 0.689449667930603\n",
            "Epoch [37/50], Loss: 0.6879730820655823\n",
            "Epoch [38/50], Loss: 0.6121582984924316\n",
            "Epoch [39/50], Loss: 0.6085260510444641\n",
            "Epoch [40/50], Loss: 0.4601573050022125\n",
            "Epoch [41/50], Loss: 0.5727658867835999\n",
            "Epoch [42/50], Loss: 0.4252921938896179\n",
            "Epoch [43/50], Loss: 0.49853044748306274\n",
            "Epoch [44/50], Loss: 0.42121022939682007\n",
            "Epoch [45/50], Loss: 0.5018198490142822\n",
            "Epoch [46/50], Loss: 0.49424391984939575\n",
            "Epoch [47/50], Loss: 0.4282950162887573\n",
            "Epoch [48/50], Loss: 0.37060850858688354\n",
            "Epoch [49/50], Loss: 0.2301291674375534\n",
            "Epoch [50/50], Loss: 0.30090194940567017\n",
            "Accuracy: 1.0, Specificity: 1.0, Sensitivity: 1.0\n",
            "\n",
            "Fold 3/10\n",
            "Epoch [1/50], Loss: 0.677951991558075\n",
            "Epoch [2/50], Loss: 0.720691442489624\n",
            "Epoch [3/50], Loss: 0.6929774284362793\n",
            "Epoch [4/50], Loss: 0.7070071697235107\n",
            "Epoch [5/50], Loss: 0.7124462723731995\n",
            "Epoch [6/50], Loss: 0.6859689950942993\n",
            "Epoch [7/50], Loss: 0.7114353179931641\n",
            "Epoch [8/50], Loss: 0.6868334412574768\n",
            "Epoch [9/50], Loss: 0.6884803175926208\n",
            "Epoch [10/50], Loss: 0.686137855052948\n",
            "Epoch [11/50], Loss: 0.7041735649108887\n",
            "Epoch [12/50], Loss: 0.6878857016563416\n",
            "Epoch [13/50], Loss: 0.7060139179229736\n",
            "Epoch [14/50], Loss: 0.6859668493270874\n",
            "Epoch [15/50], Loss: 0.7272198796272278\n",
            "Epoch [16/50], Loss: 0.7157564759254456\n",
            "Epoch [17/50], Loss: 0.7116572260856628\n",
            "Epoch [18/50], Loss: 0.6918213963508606\n",
            "Epoch [19/50], Loss: 0.7023321390151978\n",
            "Epoch [20/50], Loss: 0.6867613196372986\n",
            "Epoch [21/50], Loss: 0.6712155938148499\n",
            "Epoch [22/50], Loss: 0.693611204624176\n",
            "Epoch [23/50], Loss: 0.6870858669281006\n",
            "Epoch [24/50], Loss: 0.6943609118461609\n",
            "Epoch [25/50], Loss: 0.6886069178581238\n",
            "Epoch [26/50], Loss: 0.698958694934845\n",
            "Epoch [27/50], Loss: 0.683654248714447\n",
            "Epoch [28/50], Loss: 0.7100581526756287\n",
            "Epoch [29/50], Loss: 0.6999837160110474\n",
            "Epoch [30/50], Loss: 0.6868376135826111\n",
            "Epoch [31/50], Loss: 0.709077775478363\n",
            "Epoch [32/50], Loss: 0.6932130455970764\n",
            "Epoch [33/50], Loss: 0.6949434876441956\n",
            "Epoch [34/50], Loss: 0.7080016732215881\n",
            "Epoch [35/50], Loss: 0.6945372223854065\n",
            "Epoch [36/50], Loss: 0.6911578178405762\n",
            "Epoch [37/50], Loss: 0.6975199580192566\n",
            "Epoch [38/50], Loss: 0.7008116245269775\n",
            "Epoch [39/50], Loss: 0.6898440718650818\n",
            "Epoch [40/50], Loss: 0.6908943057060242\n",
            "Epoch [41/50], Loss: 0.6954954862594604\n",
            "Epoch [42/50], Loss: 0.700728178024292\n",
            "Epoch [43/50], Loss: 0.6902819275856018\n",
            "Epoch [44/50], Loss: 0.6997549533843994\n",
            "Epoch [45/50], Loss: 0.6966424584388733\n",
            "Epoch [46/50], Loss: 0.6920583248138428\n",
            "Epoch [47/50], Loss: 0.6959430575370789\n",
            "Epoch [48/50], Loss: 0.6837577223777771\n",
            "Epoch [49/50], Loss: 0.7049817442893982\n",
            "Epoch [50/50], Loss: 0.7068942189216614\n",
            "Accuracy: 0.4965277777777778, Specificity: 0.9930555555555556, Sensitivity: 0.0\n",
            "\n",
            "Fold 4/10\n",
            "Epoch [1/50], Loss: 0.6913334131240845\n",
            "Epoch [2/50], Loss: 0.7246389985084534\n",
            "Epoch [3/50], Loss: 0.6877725124359131\n",
            "Epoch [4/50], Loss: 0.6982392072677612\n",
            "Epoch [5/50], Loss: 0.6878854036331177\n",
            "Epoch [6/50], Loss: 0.6909822821617126\n",
            "Epoch [7/50], Loss: 0.6886311173439026\n",
            "Epoch [8/50], Loss: 0.705712616443634\n",
            "Epoch [9/50], Loss: 0.6989097595214844\n",
            "Epoch [10/50], Loss: 0.6867490410804749\n",
            "Epoch [11/50], Loss: 0.6898878216743469\n",
            "Epoch [12/50], Loss: 0.6974424123764038\n",
            "Epoch [13/50], Loss: 0.6929466724395752\n",
            "Epoch [14/50], Loss: 0.699199378490448\n",
            "Epoch [15/50], Loss: 0.7011812925338745\n",
            "Epoch [16/50], Loss: 0.6876298785209656\n",
            "Epoch [17/50], Loss: 0.6979200839996338\n",
            "Epoch [18/50], Loss: 0.6887747049331665\n",
            "Epoch [19/50], Loss: 0.6880601644515991\n",
            "Epoch [20/50], Loss: 0.6997798681259155\n",
            "Epoch [21/50], Loss: 0.6929134726524353\n",
            "Epoch [22/50], Loss: 0.696518063545227\n",
            "Epoch [23/50], Loss: 0.6884303689002991\n",
            "Epoch [24/50], Loss: 0.6930501461029053\n",
            "Epoch [25/50], Loss: 0.6926568746566772\n",
            "Epoch [26/50], Loss: 0.6897712349891663\n",
            "Epoch [27/50], Loss: 0.69675213098526\n",
            "Epoch [28/50], Loss: 0.7026194334030151\n",
            "Epoch [29/50], Loss: 0.6976140141487122\n",
            "Epoch [30/50], Loss: 0.6967472434043884\n",
            "Epoch [31/50], Loss: 0.696539044380188\n",
            "Epoch [32/50], Loss: 0.7011873126029968\n",
            "Epoch [33/50], Loss: 0.6892962455749512\n",
            "Epoch [34/50], Loss: 0.6994320750236511\n",
            "Epoch [35/50], Loss: 0.6931071281433105\n",
            "Epoch [36/50], Loss: 0.6983599066734314\n",
            "Epoch [37/50], Loss: 0.6944798231124878\n",
            "Epoch [38/50], Loss: 0.6928331255912781\n",
            "Epoch [39/50], Loss: 0.6926172971725464\n",
            "Epoch [40/50], Loss: 0.7060084939002991\n",
            "Epoch [41/50], Loss: 0.6983132362365723\n",
            "Epoch [42/50], Loss: 0.694603681564331\n",
            "Epoch [43/50], Loss: 0.6918116211891174\n",
            "Epoch [44/50], Loss: 0.695162832736969\n",
            "Epoch [45/50], Loss: 0.6968569159507751\n",
            "Epoch [46/50], Loss: 0.696345329284668\n",
            "Epoch [47/50], Loss: 0.6909945607185364\n",
            "Epoch [48/50], Loss: 0.6904222369194031\n",
            "Epoch [49/50], Loss: 0.6931077241897583\n",
            "Epoch [50/50], Loss: 0.6961110830307007\n",
            "Accuracy: 0.5, Specificity: 0.9930555555555556, Sensitivity: 0.006944444444444444\n",
            "\n",
            "Fold 5/10\n",
            "Epoch [1/50], Loss: 0.7194894552230835\n",
            "Epoch [2/50], Loss: 0.7124704122543335\n",
            "Epoch [3/50], Loss: 0.7039387226104736\n",
            "Epoch [4/50], Loss: 0.6699168682098389\n",
            "Epoch [5/50], Loss: 0.751515805721283\n",
            "Epoch [6/50], Loss: 0.7168056964874268\n",
            "Epoch [7/50], Loss: 0.7621943950653076\n",
            "Epoch [8/50], Loss: 0.7196095585823059\n",
            "Epoch [9/50], Loss: 0.68803870677948\n",
            "Epoch [10/50], Loss: 0.6947349905967712\n",
            "Epoch [11/50], Loss: 0.6613703370094299\n",
            "Epoch [12/50], Loss: 0.6930248141288757\n",
            "Epoch [13/50], Loss: 0.7351187467575073\n",
            "Epoch [14/50], Loss: 0.7079641819000244\n",
            "Epoch [15/50], Loss: 0.7161011695861816\n",
            "Epoch [16/50], Loss: 0.6898658871650696\n",
            "Epoch [17/50], Loss: 0.6809585690498352\n",
            "Epoch [18/50], Loss: 0.7135336995124817\n",
            "Epoch [19/50], Loss: 0.7051991820335388\n",
            "Epoch [20/50], Loss: 0.692911684513092\n",
            "Epoch [21/50], Loss: 0.6676304936408997\n",
            "Epoch [22/50], Loss: 0.6949660181999207\n",
            "Epoch [23/50], Loss: 0.6805104613304138\n",
            "Epoch [24/50], Loss: 0.603876531124115\n",
            "Epoch [25/50], Loss: 0.6413366794586182\n",
            "Epoch [26/50], Loss: 0.6484420895576477\n",
            "Epoch [27/50], Loss: 0.6305981874465942\n",
            "Epoch [28/50], Loss: 0.4565165042877197\n",
            "Epoch [29/50], Loss: 0.4938638508319855\n",
            "Epoch [30/50], Loss: 0.578456461429596\n",
            "Epoch [31/50], Loss: 0.47133105993270874\n",
            "Epoch [32/50], Loss: 0.4159553349018097\n",
            "Epoch [33/50], Loss: 0.3920134902000427\n",
            "Epoch [34/50], Loss: 0.5120694637298584\n",
            "Epoch [35/50], Loss: 0.39064598083496094\n",
            "Epoch [36/50], Loss: 0.20707018673419952\n",
            "Epoch [37/50], Loss: 0.33896154165267944\n",
            "Epoch [38/50], Loss: 0.336315393447876\n",
            "Epoch [39/50], Loss: 0.3280923366546631\n",
            "Epoch [40/50], Loss: 0.27877378463745117\n",
            "Epoch [41/50], Loss: 0.3518683910369873\n",
            "Epoch [42/50], Loss: 0.26951152086257935\n",
            "Epoch [43/50], Loss: 0.2428533136844635\n",
            "Epoch [44/50], Loss: 0.31624650955200195\n",
            "Epoch [45/50], Loss: 0.24792666733264923\n",
            "Epoch [46/50], Loss: 0.22904779016971588\n",
            "Epoch [47/50], Loss: 0.10265025496482849\n",
            "Epoch [48/50], Loss: 0.22564101219177246\n",
            "Epoch [49/50], Loss: 0.2094818651676178\n",
            "Epoch [50/50], Loss: 0.27567076683044434\n",
            "Accuracy: 0.9895833333333334, Specificity: 1.0, Sensitivity: 0.9791666666666666\n",
            "\n",
            "Fold 6/10\n",
            "Epoch [1/50], Loss: 0.7105770707130432\n",
            "Epoch [2/50], Loss: 0.7141335010528564\n",
            "Epoch [3/50], Loss: 0.7275829911231995\n",
            "Epoch [4/50], Loss: 0.7456877827644348\n",
            "Epoch [5/50], Loss: 0.7341294288635254\n",
            "Epoch [6/50], Loss: 0.7016817331314087\n",
            "Epoch [7/50], Loss: 0.6996191740036011\n",
            "Epoch [8/50], Loss: 0.7341282963752747\n",
            "Epoch [9/50], Loss: 0.7225764989852905\n",
            "Epoch [10/50], Loss: 0.6843352317810059\n",
            "Epoch [11/50], Loss: 0.7130424380302429\n",
            "Epoch [12/50], Loss: 0.6958559155464172\n",
            "Epoch [13/50], Loss: 0.7096798419952393\n",
            "Epoch [14/50], Loss: 0.68306565284729\n",
            "Epoch [15/50], Loss: 0.717068612575531\n",
            "Epoch [16/50], Loss: 0.6940464377403259\n",
            "Epoch [17/50], Loss: 0.7532681226730347\n",
            "Epoch [18/50], Loss: 0.7109172940254211\n",
            "Epoch [19/50], Loss: 0.7020801901817322\n",
            "Epoch [20/50], Loss: 0.6844038963317871\n",
            "Epoch [21/50], Loss: 0.7210843563079834\n",
            "Epoch [22/50], Loss: 0.7043561339378357\n",
            "Epoch [23/50], Loss: 0.696705162525177\n",
            "Epoch [24/50], Loss: 0.6759131550788879\n",
            "Epoch [25/50], Loss: 0.6998953819274902\n",
            "Epoch [26/50], Loss: 0.669342577457428\n",
            "Epoch [27/50], Loss: 0.628777265548706\n",
            "Epoch [28/50], Loss: 0.6391785740852356\n",
            "Epoch [29/50], Loss: 0.5742678046226501\n",
            "Epoch [30/50], Loss: 0.5296323895454407\n",
            "Epoch [31/50], Loss: 0.565789520740509\n",
            "Epoch [32/50], Loss: 0.44218719005584717\n",
            "Epoch [33/50], Loss: 0.550757646560669\n",
            "Epoch [34/50], Loss: 0.5085883140563965\n",
            "Epoch [35/50], Loss: 0.40213823318481445\n",
            "Epoch [36/50], Loss: 0.42431771755218506\n",
            "Epoch [37/50], Loss: 0.4414730370044708\n",
            "Epoch [38/50], Loss: 0.40507346391677856\n",
            "Epoch [39/50], Loss: 0.5262081623077393\n",
            "Epoch [40/50], Loss: 0.43956735730171204\n",
            "Epoch [41/50], Loss: 0.46996426582336426\n",
            "Epoch [42/50], Loss: 0.5274049639701843\n",
            "Epoch [43/50], Loss: 0.421305388212204\n",
            "Epoch [44/50], Loss: 0.4685182571411133\n",
            "Epoch [45/50], Loss: 0.474098801612854\n",
            "Epoch [46/50], Loss: 0.4342743456363678\n",
            "Epoch [47/50], Loss: 0.5109443068504333\n",
            "Epoch [48/50], Loss: 0.3742665648460388\n",
            "Epoch [49/50], Loss: 0.4626850485801697\n",
            "Epoch [50/50], Loss: 0.40752124786376953\n",
            "Accuracy: 0.9166666666666666, Specificity: 0.8333333333333334, Sensitivity: 1.0\n",
            "\n",
            "Fold 7/10\n",
            "Epoch [1/50], Loss: 0.7317212820053101\n",
            "Epoch [2/50], Loss: 0.7117049098014832\n",
            "Epoch [3/50], Loss: 0.67996746301651\n",
            "Epoch [4/50], Loss: 0.6974104046821594\n",
            "Epoch [5/50], Loss: 0.7345430850982666\n",
            "Epoch [6/50], Loss: 0.6911869645118713\n",
            "Epoch [7/50], Loss: 0.6709212064743042\n",
            "Epoch [8/50], Loss: 0.7104207873344421\n",
            "Epoch [9/50], Loss: 0.6816723346710205\n",
            "Epoch [10/50], Loss: 0.6910201907157898\n",
            "Epoch [11/50], Loss: 0.6788709163665771\n",
            "Epoch [12/50], Loss: 0.6956978440284729\n",
            "Epoch [13/50], Loss: 0.7021872401237488\n",
            "Epoch [14/50], Loss: 0.7210556864738464\n",
            "Epoch [15/50], Loss: 0.7031683921813965\n",
            "Epoch [16/50], Loss: 0.6642482876777649\n",
            "Epoch [17/50], Loss: 0.7176089882850647\n",
            "Epoch [18/50], Loss: 0.6978781223297119\n",
            "Epoch [19/50], Loss: 0.7091125845909119\n",
            "Epoch [20/50], Loss: 0.700977623462677\n",
            "Epoch [21/50], Loss: 0.6812383532524109\n",
            "Epoch [22/50], Loss: 0.6884481906890869\n",
            "Epoch [23/50], Loss: 0.6704590320587158\n",
            "Epoch [24/50], Loss: 0.7231130599975586\n",
            "Epoch [25/50], Loss: 0.6163742542266846\n",
            "Epoch [26/50], Loss: 0.6547908186912537\n",
            "Epoch [27/50], Loss: 0.5616151690483093\n",
            "Epoch [28/50], Loss: 0.611372172832489\n",
            "Epoch [29/50], Loss: 0.635566771030426\n",
            "Epoch [30/50], Loss: 0.7098754644393921\n",
            "Epoch [31/50], Loss: 0.5419353246688843\n",
            "Epoch [32/50], Loss: 0.5728878378868103\n",
            "Epoch [33/50], Loss: 0.4368690550327301\n",
            "Epoch [34/50], Loss: 0.4085674285888672\n",
            "Epoch [35/50], Loss: 0.34850600361824036\n",
            "Epoch [36/50], Loss: 0.4035210907459259\n",
            "Epoch [37/50], Loss: 0.41136837005615234\n",
            "Epoch [38/50], Loss: 0.35376590490341187\n",
            "Epoch [39/50], Loss: 0.2846873700618744\n",
            "Epoch [40/50], Loss: 0.2874770164489746\n",
            "Epoch [41/50], Loss: 0.3723945915699005\n",
            "Epoch [42/50], Loss: 0.2747054696083069\n",
            "Epoch [43/50], Loss: 0.2840035557746887\n",
            "Epoch [44/50], Loss: 0.23542991280555725\n",
            "Epoch [45/50], Loss: 0.26133114099502563\n",
            "Epoch [46/50], Loss: 0.26975107192993164\n",
            "Epoch [47/50], Loss: 0.16393446922302246\n",
            "Epoch [48/50], Loss: 0.3394237756729126\n",
            "Epoch [49/50], Loss: 0.2636478543281555\n",
            "Epoch [50/50], Loss: 0.19362932443618774\n",
            "Accuracy: 0.9965277777777778, Specificity: 1.0, Sensitivity: 0.9930555555555556\n",
            "\n",
            "Fold 8/10\n",
            "Epoch [1/50], Loss: 0.7660545110702515\n",
            "Epoch [2/50], Loss: 0.7431731224060059\n",
            "Epoch [3/50], Loss: 0.6843968629837036\n",
            "Epoch [4/50], Loss: 0.7275699377059937\n",
            "Epoch [5/50], Loss: 0.6635813117027283\n",
            "Epoch [6/50], Loss: 0.6799007654190063\n",
            "Epoch [7/50], Loss: 0.6999607086181641\n",
            "Epoch [8/50], Loss: 0.7026745080947876\n",
            "Epoch [9/50], Loss: 0.718040406703949\n",
            "Epoch [10/50], Loss: 0.6592944860458374\n",
            "Epoch [11/50], Loss: 0.7482582330703735\n",
            "Epoch [12/50], Loss: 0.691031813621521\n",
            "Epoch [13/50], Loss: 0.6684244871139526\n",
            "Epoch [14/50], Loss: 0.7316722869873047\n",
            "Epoch [15/50], Loss: 0.695891261100769\n",
            "Epoch [16/50], Loss: 0.7044699788093567\n",
            "Epoch [17/50], Loss: 0.6846476197242737\n",
            "Epoch [18/50], Loss: 0.7126882672309875\n",
            "Epoch [19/50], Loss: 0.6964284777641296\n",
            "Epoch [20/50], Loss: 0.7096322178840637\n",
            "Epoch [21/50], Loss: 0.7104372978210449\n",
            "Epoch [22/50], Loss: 0.6822382211685181\n",
            "Epoch [23/50], Loss: 0.6701648831367493\n",
            "Epoch [24/50], Loss: 0.5797173976898193\n",
            "Epoch [25/50], Loss: 0.5912550687789917\n",
            "Epoch [26/50], Loss: 0.6533147692680359\n",
            "Epoch [27/50], Loss: 0.6052491068840027\n",
            "Epoch [28/50], Loss: 0.6286206841468811\n",
            "Epoch [29/50], Loss: 0.5766782760620117\n",
            "Epoch [30/50], Loss: 0.5367370843887329\n",
            "Epoch [31/50], Loss: 0.584433376789093\n",
            "Epoch [32/50], Loss: 0.5408372282981873\n",
            "Epoch [33/50], Loss: 0.45277896523475647\n",
            "Epoch [34/50], Loss: 0.43056342005729675\n",
            "Epoch [35/50], Loss: 0.46219402551651\n",
            "Epoch [36/50], Loss: 0.5022004842758179\n",
            "Epoch [37/50], Loss: 0.4174981415271759\n",
            "Epoch [38/50], Loss: 0.3729892373085022\n",
            "Epoch [39/50], Loss: 0.3712467551231384\n",
            "Epoch [40/50], Loss: 0.5296612977981567\n",
            "Epoch [41/50], Loss: 0.4955000579357147\n",
            "Epoch [42/50], Loss: 0.3047059178352356\n",
            "Epoch [43/50], Loss: 0.44026467204093933\n",
            "Epoch [44/50], Loss: 0.39429134130477905\n",
            "Epoch [45/50], Loss: 0.3639567494392395\n",
            "Epoch [46/50], Loss: 0.3791657090187073\n",
            "Epoch [47/50], Loss: 0.550801694393158\n",
            "Epoch [48/50], Loss: 0.34344038367271423\n",
            "Epoch [49/50], Loss: 0.41428127884864807\n",
            "Epoch [50/50], Loss: 0.4911121129989624\n",
            "Accuracy: 0.9618055555555556, Specificity: 0.9305555555555556, Sensitivity: 0.9930555555555556\n",
            "\n",
            "Fold 9/10\n",
            "Epoch [1/50], Loss: 0.7634207010269165\n",
            "Epoch [2/50], Loss: 0.716494619846344\n",
            "Epoch [3/50], Loss: 0.6355915665626526\n",
            "Epoch [4/50], Loss: 0.723030686378479\n",
            "Epoch [5/50], Loss: 0.7294609546661377\n",
            "Epoch [6/50], Loss: 0.6385403275489807\n",
            "Epoch [7/50], Loss: 0.6610105037689209\n",
            "Epoch [8/50], Loss: 0.679857611656189\n",
            "Epoch [9/50], Loss: 0.7051633596420288\n",
            "Epoch [10/50], Loss: 0.6567936539649963\n",
            "Epoch [11/50], Loss: 0.706172525882721\n",
            "Epoch [12/50], Loss: 0.6884779334068298\n",
            "Epoch [13/50], Loss: 0.6906065344810486\n",
            "Epoch [14/50], Loss: 0.7087626457214355\n",
            "Epoch [15/50], Loss: 0.6751825213432312\n",
            "Epoch [16/50], Loss: 0.6710338592529297\n",
            "Epoch [17/50], Loss: 0.667256236076355\n",
            "Epoch [18/50], Loss: 0.722705602645874\n",
            "Epoch [19/50], Loss: 0.6844972968101501\n",
            "Epoch [20/50], Loss: 0.698550283908844\n",
            "Epoch [21/50], Loss: 0.690041184425354\n",
            "Epoch [22/50], Loss: 0.6950648427009583\n",
            "Epoch [23/50], Loss: 0.7003047466278076\n",
            "Epoch [24/50], Loss: 0.6879777312278748\n",
            "Epoch [25/50], Loss: 0.6873112320899963\n",
            "Epoch [26/50], Loss: 0.6989169120788574\n",
            "Epoch [27/50], Loss: 0.7092564105987549\n",
            "Epoch [28/50], Loss: 0.7269551157951355\n",
            "Epoch [29/50], Loss: 0.6652854681015015\n",
            "Epoch [30/50], Loss: 0.6769647598266602\n",
            "Epoch [31/50], Loss: 0.6799284815788269\n",
            "Epoch [32/50], Loss: 0.7108050584793091\n",
            "Epoch [33/50], Loss: 0.6650027632713318\n",
            "Epoch [34/50], Loss: 0.6828615665435791\n",
            "Epoch [35/50], Loss: 0.6997286677360535\n",
            "Epoch [36/50], Loss: 0.6664164066314697\n",
            "Epoch [37/50], Loss: 0.6766272187232971\n",
            "Epoch [38/50], Loss: 0.6137207746505737\n",
            "Epoch [39/50], Loss: 0.6849032044410706\n",
            "Epoch [40/50], Loss: 0.5983667969703674\n",
            "Epoch [41/50], Loss: 0.5955182909965515\n",
            "Epoch [42/50], Loss: 0.624605655670166\n",
            "Epoch [43/50], Loss: 0.6606704592704773\n",
            "Epoch [44/50], Loss: 0.5167662501335144\n",
            "Epoch [45/50], Loss: 0.5021213889122009\n",
            "Epoch [46/50], Loss: 0.49580898880958557\n",
            "Epoch [47/50], Loss: 0.47530263662338257\n",
            "Epoch [48/50], Loss: 0.44652843475341797\n",
            "Epoch [49/50], Loss: 0.5251068472862244\n",
            "Epoch [50/50], Loss: 0.480302631855011\n",
            "Accuracy: 0.8958333333333334, Specificity: 0.7916666666666666, Sensitivity: 1.0\n",
            "\n",
            "Fold 10/10\n",
            "Epoch [1/50], Loss: 0.7190877795219421\n",
            "Epoch [2/50], Loss: 0.7000917792320251\n",
            "Epoch [3/50], Loss: 0.7009332180023193\n",
            "Epoch [4/50], Loss: 0.7075750827789307\n",
            "Epoch [5/50], Loss: 0.6815115809440613\n",
            "Epoch [6/50], Loss: 0.6796754002571106\n",
            "Epoch [7/50], Loss: 0.7018500566482544\n",
            "Epoch [8/50], Loss: 0.6922414898872375\n",
            "Epoch [9/50], Loss: 0.6996292471885681\n",
            "Epoch [10/50], Loss: 0.6937960386276245\n",
            "Epoch [11/50], Loss: 0.6961071491241455\n",
            "Epoch [12/50], Loss: 0.6971626877784729\n",
            "Epoch [13/50], Loss: 0.6864061951637268\n",
            "Epoch [14/50], Loss: 0.6973294615745544\n",
            "Epoch [15/50], Loss: 0.696712076663971\n",
            "Epoch [16/50], Loss: 0.6994649767875671\n",
            "Epoch [17/50], Loss: 0.7050938606262207\n",
            "Epoch [18/50], Loss: 0.6893408894538879\n",
            "Epoch [19/50], Loss: 0.6858245730400085\n",
            "Epoch [20/50], Loss: 0.7014384865760803\n",
            "Epoch [21/50], Loss: 0.6771583557128906\n",
            "Epoch [22/50], Loss: 0.6841849088668823\n",
            "Epoch [23/50], Loss: 0.6919998526573181\n",
            "Epoch [24/50], Loss: 0.6775897145271301\n",
            "Epoch [25/50], Loss: 0.642377495765686\n",
            "Epoch [26/50], Loss: 0.6300612092018127\n",
            "Epoch [27/50], Loss: 0.5875208973884583\n",
            "Epoch [28/50], Loss: 0.3993065357208252\n",
            "Epoch [29/50], Loss: 0.5360177755355835\n",
            "Epoch [30/50], Loss: 0.48747703433036804\n",
            "Epoch [31/50], Loss: 0.5565112829208374\n",
            "Epoch [32/50], Loss: 0.5381497740745544\n",
            "Epoch [33/50], Loss: 0.42675912380218506\n",
            "Epoch [34/50], Loss: 0.43758878111839294\n",
            "Epoch [35/50], Loss: 0.4594763517379761\n",
            "Epoch [36/50], Loss: 0.46110618114471436\n",
            "Epoch [37/50], Loss: 0.3937414884567261\n",
            "Epoch [38/50], Loss: 0.48555365204811096\n",
            "Epoch [39/50], Loss: 0.4251425862312317\n",
            "Epoch [40/50], Loss: 0.36827656626701355\n",
            "Epoch [41/50], Loss: 0.5530638098716736\n",
            "Epoch [42/50], Loss: 0.3791741132736206\n",
            "Epoch [43/50], Loss: 0.4809720516204834\n",
            "Epoch [44/50], Loss: 0.37401920557022095\n",
            "Epoch [45/50], Loss: 0.32361510396003723\n",
            "Epoch [46/50], Loss: 0.40691274404525757\n",
            "Epoch [47/50], Loss: 0.39310410618782043\n",
            "Epoch [48/50], Loss: 0.28711503744125366\n",
            "Epoch [49/50], Loss: 0.29048722982406616\n",
            "Epoch [50/50], Loss: 0.31198257207870483\n",
            "Accuracy: 0.8888888888888888, Specificity: 0.7777777777777778, Sensitivity: 1.0\n",
            "\n",
            "Average Accuracy: 0.8645833333333333\n",
            "Average Specificity: 0.9319444444444445\n",
            "Average Sensitivity: 0.7972222222222223\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the evaluation metrics\n",
        "def calculate_metrics(conf_matrix):\n",
        "    true_positive = conf_matrix[1, 1]\n",
        "    true_negative = conf_matrix[0, 0]\n",
        "    false_positive = conf_matrix[0, 1]\n",
        "    false_negative = conf_matrix[1, 0]\n",
        "\n",
        "    accuracy = (true_positive + true_negative) / np.sum(conf_matrix)\n",
        "    specificity = true_negative / (true_negative + false_positive)\n",
        "    sensitivity = true_positive / (true_positive + false_negative)\n",
        "\n",
        "    return accuracy, specificity, sensitivity\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "num_folds = 10\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "cnn_accuracies = []\n",
        "cnn_specificities = []\n",
        "cnn_sensitivities = []\n",
        "cnn_loss_history = [[0 for x in range(50)] for y in range(10)]\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(data, labels)):\n",
        "    print(f\"Fold {fold+1}/{num_folds}\")\n",
        "\n",
        "    # Create data and labels subsets for this fold\n",
        "    train_data, test_data = data[train_idx], data[test_idx]\n",
        "    train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Convert data and labels to PyTorch tensors\n",
        "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "    # Create DataLoader for training\n",
        "    train_dataset = TensorDataset(train_data, train_labels)\n",
        "    batch_size = 32\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Create the model instance\n",
        "    model = PDCNN()\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Assuming it's a classification task\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 50\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_data, batch_labels in train_dataloader:\n",
        "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_data)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            cnn_loss_history[fold].append(loss.item())\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data = test_data.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        predictions = model(test_data)\n",
        "        _, predicted_labels = torch.max(predictions, 1)\n",
        "        conf_matrix = confusion_matrix(test_labels.cpu(), predicted_labels.cpu())\n",
        "        accuracy, specificity, sensitivity = calculate_metrics(conf_matrix)\n",
        "        cnn_accuracies.append(accuracy)\n",
        "        cnn_specificities.append(specificity)\n",
        "        cnn_sensitivities.append(sensitivity)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}, Specificity: {specificity}, Sensitivity: {sensitivity}\\n\")\n",
        "\n",
        "# Calculate average metrics over all folds\n",
        "avg_accuracy = np.mean(cnn_accuracies)\n",
        "avg_specificity = np.mean(cnn_specificities)\n",
        "avg_sensitivity = np.mean(cnn_sensitivities)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}\")\n",
        "print(f\"Average Specificity: {avg_specificity}\")\n",
        "print(f\"Average Sensitivity: {avg_sensitivity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K62GhuRBHka7"
      },
      "outputs": [],
      "source": [
        "#LSTM results\n",
        "cnn_results = {\n",
        "        'accuracies': cnn_accuracies,\n",
        "        'sensitivities': cnn_sensitivities,\n",
        "        'specificities': cnn_specificities\n",
        "    }\n",
        "\n",
        "np.save(base_path + \"cnn_results.npy\", cnn_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKOVGgNSTjRW"
      },
      "outputs": [],
      "source": [
        "np.save(base_path + \"cnn_loss.npy\", cnn_loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsxiUPV6Vf1u"
      },
      "source": [
        "#SincNet Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFMloRpuM1r1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SincConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, sample_rate):\n",
        "        super(SincConv, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.sample_rate = sample_rate\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Define the bandpass parameters as learnable parameters\n",
        "        self.center_frequencies = nn.Parameter(torch.rand(out_channels) * (sample_rate / 2))\n",
        "\n",
        "        # Initialize the other required parameters\n",
        "        self.window = nn.Parameter(torch.hann_window(kernel_size))\n",
        "        self.bands = nn.Parameter(torch.exp(torch.linspace(torch.log(torch.tensor(20.0)), torch.log(torch.tensor(sample_rate / 2.0)), out_channels)))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Create sinc filters based on the learnable parameters\n",
        "        filters = (2 * self.center_frequencies.view(-1, 1) * self.bands.view(1, -1) * torch.sinc(\n",
        "            2 * self.center_frequencies.view(-1, 1) * (torch.arange(self.kernel_size).float() - (self.kernel_size - 1) / 2)\n",
        "        )).to(x.device)\n",
        "\n",
        "        # Apply the filters using convolution\n",
        "        x = x.unsqueeze(1)  # Add a channel dimension\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = F.conv1d(x, filters.unsqueeze(1))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR_luadBVoFb"
      },
      "outputs": [],
      "source": [
        "class PDSincNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PDSincNet, self).__init__()\n",
        "\n",
        "        self.sincconv1 = SincConv(in_channels=41, out_channels=5, kernel_size=5, sample_rate=512.0)\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels=5, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=15, kernel_size=5, stride=1)\n",
        "        self.maxpool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=39270, out_features=20)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=20, out_features=10)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(in_features=10, out_features=2)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool1(torch.relu(self.sincconv1(x)))\n",
        "        x = self.maxpool2(torch.relu(self.conv2(x)))\n",
        "        x = self.maxpool3(torch.relu(self.conv3(x)))\n",
        "        x = self.maxpool4(torch.relu(self.conv4(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
        "        x = self.dropout2(torch.relu(self.fc2(x)))\n",
        "        x = self.dropout3(self.fc3(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AealyixWKCT",
        "outputId": "877296c8-9782-403d-f424-d4d4ac60313a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n",
            "Epoch [1/50], Loss: 0.6529732942581177\n",
            "Epoch [2/50], Loss: 0.6580419540405273\n",
            "Epoch [3/50], Loss: 0.6455066800117493\n",
            "Epoch [4/50], Loss: 0.5523369312286377\n",
            "Epoch [5/50], Loss: 0.712159276008606\n",
            "Epoch [6/50], Loss: 0.5658066868782043\n",
            "Epoch [7/50], Loss: 0.5250038504600525\n",
            "Epoch [8/50], Loss: 0.560652494430542\n",
            "Epoch [9/50], Loss: 1.899572491645813\n",
            "Epoch [10/50], Loss: 1.3737211227416992\n",
            "Epoch [11/50], Loss: 0.49885597825050354\n",
            "Epoch [12/50], Loss: 0.40681102871894836\n",
            "Epoch [13/50], Loss: 0.5168861150741577\n",
            "Epoch [14/50], Loss: 0.49427586793899536\n",
            "Epoch [15/50], Loss: 0.40390461683273315\n",
            "Epoch [16/50], Loss: 0.5146915316581726\n",
            "Epoch [17/50], Loss: 0.4515836536884308\n",
            "Epoch [18/50], Loss: 0.48524177074432373\n",
            "Epoch [19/50], Loss: 0.48692458868026733\n",
            "Epoch [20/50], Loss: 0.3816578686237335\n",
            "Epoch [21/50], Loss: 0.40912961959838867\n",
            "Epoch [22/50], Loss: 0.3882577121257782\n",
            "Epoch [23/50], Loss: 0.4451031982898712\n",
            "Epoch [24/50], Loss: 0.39054983854293823\n",
            "Epoch [25/50], Loss: 0.423153817653656\n",
            "Epoch [26/50], Loss: 0.4890359342098236\n",
            "Epoch [27/50], Loss: 0.38174712657928467\n",
            "Epoch [28/50], Loss: 0.4724765121936798\n",
            "Epoch [29/50], Loss: 0.31878551840782166\n",
            "Epoch [30/50], Loss: 0.3121996819972992\n",
            "Epoch [31/50], Loss: 0.3895761966705322\n",
            "Epoch [32/50], Loss: 0.4565512537956238\n",
            "Epoch [33/50], Loss: 0.4722684621810913\n",
            "Epoch [34/50], Loss: 0.30746328830718994\n",
            "Epoch [35/50], Loss: 0.48987048864364624\n",
            "Epoch [36/50], Loss: 0.3599173128604889\n",
            "Epoch [37/50], Loss: 0.41378462314605713\n",
            "Epoch [38/50], Loss: 0.46493732929229736\n",
            "Epoch [39/50], Loss: 0.4388573169708252\n",
            "Epoch [40/50], Loss: 0.35880959033966064\n",
            "Epoch [41/50], Loss: 0.44019055366516113\n",
            "Epoch [42/50], Loss: 0.3729233741760254\n",
            "Epoch [43/50], Loss: 0.43881210684776306\n",
            "Epoch [44/50], Loss: 0.41290420293807983\n",
            "Epoch [45/50], Loss: 0.39302921295166016\n",
            "Epoch [46/50], Loss: 0.3900986313819885\n",
            "Epoch [47/50], Loss: 0.39770007133483887\n",
            "Epoch [48/50], Loss: 0.36444705724716187\n",
            "Epoch [49/50], Loss: 0.35457152128219604\n",
            "Epoch [50/50], Loss: 0.29874831438064575\n",
            "Accuracy: 0.9895833333333334, Specificity: 0.9791666666666666, Sensitivity: 1.0\n",
            "\n",
            "Fold 2/10\n",
            "Epoch [1/50], Loss: 0.6305599212646484\n",
            "Epoch [2/50], Loss: 0.5519195199012756\n",
            "Epoch [3/50], Loss: 0.5933554768562317\n",
            "Epoch [4/50], Loss: 0.4359542429447174\n",
            "Epoch [5/50], Loss: 0.48921170830726624\n",
            "Epoch [6/50], Loss: 0.6521068215370178\n",
            "Epoch [7/50], Loss: 0.607611894607544\n",
            "Epoch [8/50], Loss: 0.4969909191131592\n",
            "Epoch [9/50], Loss: 0.6249430775642395\n",
            "Epoch [10/50], Loss: 0.44933027029037476\n",
            "Epoch [11/50], Loss: 0.5232225656509399\n",
            "Epoch [12/50], Loss: 0.47925376892089844\n",
            "Epoch [13/50], Loss: 0.5370745658874512\n",
            "Epoch [14/50], Loss: 0.5083457827568054\n",
            "Epoch [15/50], Loss: 0.551029622554779\n",
            "Epoch [16/50], Loss: 0.5509268641471863\n",
            "Epoch [17/50], Loss: 0.7269355654716492\n",
            "Epoch [18/50], Loss: 0.45802217721939087\n",
            "Epoch [19/50], Loss: 0.5450295209884644\n",
            "Epoch [20/50], Loss: 0.43564340472221375\n",
            "Epoch [21/50], Loss: 0.5319397449493408\n",
            "Epoch [22/50], Loss: 0.4595772624015808\n",
            "Epoch [23/50], Loss: 0.4963545501232147\n",
            "Epoch [24/50], Loss: 0.47576653957366943\n",
            "Epoch [25/50], Loss: 0.4909335970878601\n",
            "Epoch [26/50], Loss: 0.42640766501426697\n",
            "Epoch [27/50], Loss: 0.4751270115375519\n",
            "Epoch [28/50], Loss: 0.40321558713912964\n",
            "Epoch [29/50], Loss: 0.37564390897750854\n",
            "Epoch [30/50], Loss: 0.4831223487854004\n",
            "Epoch [31/50], Loss: 0.38258010149002075\n",
            "Epoch [32/50], Loss: 0.46311116218566895\n",
            "Epoch [33/50], Loss: 0.4237009882926941\n",
            "Epoch [34/50], Loss: 0.4204028248786926\n",
            "Epoch [35/50], Loss: 0.4260783791542053\n",
            "Epoch [36/50], Loss: 0.48646026849746704\n",
            "Epoch [37/50], Loss: 0.38305386900901794\n",
            "Epoch [38/50], Loss: 0.41290563344955444\n",
            "Epoch [39/50], Loss: 0.4457349479198456\n",
            "Epoch [40/50], Loss: 0.4571433663368225\n",
            "Epoch [41/50], Loss: 0.3888667821884155\n",
            "Epoch [42/50], Loss: 0.46575266122817993\n",
            "Epoch [43/50], Loss: 0.3955199718475342\n",
            "Epoch [44/50], Loss: 0.5128609538078308\n",
            "Epoch [45/50], Loss: 0.2970501482486725\n",
            "Epoch [46/50], Loss: 0.3748297691345215\n",
            "Epoch [47/50], Loss: 0.35246700048446655\n",
            "Epoch [48/50], Loss: 0.4379884600639343\n",
            "Epoch [49/50], Loss: 0.4238916337490082\n",
            "Epoch [50/50], Loss: 0.3692170977592468\n",
            "Accuracy: 0.9930555555555556, Specificity: 0.9861111111111112, Sensitivity: 1.0\n",
            "\n",
            "Fold 3/10\n",
            "Epoch [1/50], Loss: 0.7354866862297058\n",
            "Epoch [2/50], Loss: 0.7011801600456238\n",
            "Epoch [3/50], Loss: 0.6588164567947388\n",
            "Epoch [4/50], Loss: 0.6355946660041809\n",
            "Epoch [5/50], Loss: 0.6185727715492249\n",
            "Epoch [6/50], Loss: 0.5739584565162659\n",
            "Epoch [7/50], Loss: 0.5687746405601501\n",
            "Epoch [8/50], Loss: 0.5401933193206787\n",
            "Epoch [9/50], Loss: 0.6254069209098816\n",
            "Epoch [10/50], Loss: 0.4628744125366211\n",
            "Epoch [11/50], Loss: 0.5628902912139893\n",
            "Epoch [12/50], Loss: 0.5574467778205872\n",
            "Epoch [13/50], Loss: 0.6346404552459717\n",
            "Epoch [14/50], Loss: 0.6162096261978149\n",
            "Epoch [15/50], Loss: 0.5068789124488831\n",
            "Epoch [16/50], Loss: 0.47703179717063904\n",
            "Epoch [17/50], Loss: 0.5644619464874268\n",
            "Epoch [18/50], Loss: 0.5555338263511658\n",
            "Epoch [19/50], Loss: 0.46346575021743774\n",
            "Epoch [20/50], Loss: 0.4375216066837311\n",
            "Epoch [21/50], Loss: 0.4476356506347656\n",
            "Epoch [22/50], Loss: 0.4942109286785126\n",
            "Epoch [23/50], Loss: 0.5044834017753601\n",
            "Epoch [24/50], Loss: 0.5192768573760986\n",
            "Epoch [25/50], Loss: 0.5367212891578674\n",
            "Epoch [26/50], Loss: 0.49706703424453735\n",
            "Epoch [27/50], Loss: 0.4362082779407501\n",
            "Epoch [28/50], Loss: 0.4284687042236328\n",
            "Epoch [29/50], Loss: 0.4679301381111145\n",
            "Epoch [30/50], Loss: 0.39846551418304443\n",
            "Epoch [31/50], Loss: 0.5042608976364136\n",
            "Epoch [32/50], Loss: 0.35115402936935425\n",
            "Epoch [33/50], Loss: 0.40799933671951294\n",
            "Epoch [34/50], Loss: 0.3613908290863037\n",
            "Epoch [35/50], Loss: 0.42313331365585327\n",
            "Epoch [36/50], Loss: 0.39293372631073\n",
            "Epoch [37/50], Loss: 0.363521546125412\n",
            "Epoch [38/50], Loss: 0.4073845446109772\n",
            "Epoch [39/50], Loss: 0.4016672372817993\n",
            "Epoch [40/50], Loss: 0.5306749939918518\n",
            "Epoch [41/50], Loss: 0.5683854222297668\n",
            "Epoch [42/50], Loss: 0.36384665966033936\n",
            "Epoch [43/50], Loss: 0.5252494215965271\n",
            "Epoch [44/50], Loss: 0.37356287240982056\n",
            "Epoch [45/50], Loss: 0.44046837091445923\n",
            "Epoch [46/50], Loss: 0.47316408157348633\n",
            "Epoch [47/50], Loss: 0.5335267186164856\n",
            "Epoch [48/50], Loss: 0.5128457546234131\n",
            "Epoch [49/50], Loss: 0.49330800771713257\n",
            "Epoch [50/50], Loss: 0.4074743986129761\n",
            "Accuracy: 0.9861111111111112, Specificity: 0.9861111111111112, Sensitivity: 0.9861111111111112\n",
            "\n",
            "Fold 4/10\n",
            "Epoch [1/50], Loss: 0.638818621635437\n",
            "Epoch [2/50], Loss: 0.6792215704917908\n",
            "Epoch [3/50], Loss: 0.6099397540092468\n",
            "Epoch [4/50], Loss: 0.5436074137687683\n",
            "Epoch [5/50], Loss: 0.45987468957901\n",
            "Epoch [6/50], Loss: 0.6030846238136292\n",
            "Epoch [7/50], Loss: 0.4425024092197418\n",
            "Epoch [8/50], Loss: 0.36755427718162537\n",
            "Epoch [9/50], Loss: 0.6445815563201904\n",
            "Epoch [10/50], Loss: 0.4971512258052826\n",
            "Epoch [11/50], Loss: 0.5328640341758728\n",
            "Epoch [12/50], Loss: 0.498066246509552\n",
            "Epoch [13/50], Loss: 0.5171387791633606\n",
            "Epoch [14/50], Loss: 0.48892641067504883\n",
            "Epoch [15/50], Loss: 0.4915096163749695\n",
            "Epoch [16/50], Loss: 0.5008885264396667\n",
            "Epoch [17/50], Loss: 0.37669429183006287\n",
            "Epoch [18/50], Loss: 0.4604671597480774\n",
            "Epoch [19/50], Loss: 0.4840441346168518\n",
            "Epoch [20/50], Loss: 0.3900229036808014\n",
            "Epoch [21/50], Loss: 0.40059009194374084\n",
            "Epoch [22/50], Loss: 0.372000128030777\n",
            "Epoch [23/50], Loss: 0.373659610748291\n",
            "Epoch [24/50], Loss: 0.5500381588935852\n",
            "Epoch [25/50], Loss: 0.44843846559524536\n",
            "Epoch [26/50], Loss: 0.4020949602127075\n",
            "Epoch [27/50], Loss: 0.43262192606925964\n",
            "Epoch [28/50], Loss: 0.45718467235565186\n",
            "Epoch [29/50], Loss: 0.3507760465145111\n",
            "Epoch [30/50], Loss: 0.360315203666687\n",
            "Epoch [31/50], Loss: 0.3037494421005249\n",
            "Epoch [32/50], Loss: 0.5621220469474792\n",
            "Epoch [33/50], Loss: 0.3164035975933075\n",
            "Epoch [34/50], Loss: 0.4502074420452118\n",
            "Epoch [35/50], Loss: 0.3571573495864868\n",
            "Epoch [36/50], Loss: 0.3573489189147949\n",
            "Epoch [37/50], Loss: 0.3770526945590973\n",
            "Epoch [38/50], Loss: 0.3805815577507019\n",
            "Epoch [39/50], Loss: 0.3438505530357361\n",
            "Epoch [40/50], Loss: 0.29864823818206787\n",
            "Epoch [41/50], Loss: 0.4228169620037079\n",
            "Epoch [42/50], Loss: 0.33668220043182373\n",
            "Epoch [43/50], Loss: 0.42110180854797363\n",
            "Epoch [44/50], Loss: 0.3884236216545105\n",
            "Epoch [45/50], Loss: 0.3857089877128601\n",
            "Epoch [46/50], Loss: 0.41201841831207275\n",
            "Epoch [47/50], Loss: 0.4554518759250641\n",
            "Epoch [48/50], Loss: 0.4620794653892517\n",
            "Epoch [49/50], Loss: 0.42124009132385254\n",
            "Epoch [50/50], Loss: 0.3032504916191101\n",
            "Accuracy: 0.9930555555555556, Specificity: 1.0, Sensitivity: 0.9861111111111112\n",
            "\n",
            "Fold 5/10\n",
            "Epoch [1/50], Loss: 0.6545946598052979\n",
            "Epoch [2/50], Loss: 0.6109097003936768\n",
            "Epoch [3/50], Loss: 0.6120507717132568\n",
            "Epoch [4/50], Loss: 0.577812910079956\n",
            "Epoch [5/50], Loss: 0.5238000750541687\n",
            "Epoch [6/50], Loss: 0.6118642687797546\n",
            "Epoch [7/50], Loss: 0.6436483263969421\n",
            "Epoch [8/50], Loss: 0.6479540467262268\n",
            "Epoch [9/50], Loss: 0.6021404266357422\n",
            "Epoch [10/50], Loss: 0.4839729070663452\n",
            "Epoch [11/50], Loss: 0.4688599407672882\n",
            "Epoch [12/50], Loss: 0.5591168999671936\n",
            "Epoch [13/50], Loss: 0.5724329352378845\n",
            "Epoch [14/50], Loss: 0.5559519529342651\n",
            "Epoch [15/50], Loss: 0.5077171325683594\n",
            "Epoch [16/50], Loss: 0.5735659003257751\n",
            "Epoch [17/50], Loss: 0.4532613158226013\n",
            "Epoch [18/50], Loss: 0.4856402277946472\n",
            "Epoch [19/50], Loss: 0.44846266508102417\n",
            "Epoch [20/50], Loss: 0.46064186096191406\n",
            "Epoch [21/50], Loss: 0.514559805393219\n",
            "Epoch [22/50], Loss: 0.5135018825531006\n",
            "Epoch [23/50], Loss: 0.513836145401001\n",
            "Epoch [24/50], Loss: 0.42808258533477783\n",
            "Epoch [25/50], Loss: 0.4534531831741333\n",
            "Epoch [26/50], Loss: 0.4764014184474945\n",
            "Epoch [27/50], Loss: 0.4341956675052643\n",
            "Epoch [28/50], Loss: 0.37287312746047974\n",
            "Epoch [29/50], Loss: 0.5026673078536987\n",
            "Epoch [30/50], Loss: 0.3595222234725952\n",
            "Epoch [31/50], Loss: 0.43750637769699097\n",
            "Epoch [32/50], Loss: 0.4250374436378479\n",
            "Epoch [33/50], Loss: 0.5116608738899231\n",
            "Epoch [34/50], Loss: 0.4242340922355652\n",
            "Epoch [35/50], Loss: 0.464620441198349\n",
            "Epoch [36/50], Loss: 0.5198392868041992\n",
            "Epoch [37/50], Loss: 0.3981406092643738\n",
            "Epoch [38/50], Loss: 0.4088439643383026\n",
            "Epoch [39/50], Loss: 0.34975624084472656\n",
            "Epoch [40/50], Loss: 0.48070502281188965\n",
            "Epoch [41/50], Loss: 0.3888590335845947\n",
            "Epoch [42/50], Loss: 0.456805020570755\n",
            "Epoch [43/50], Loss: 0.3678249716758728\n",
            "Epoch [44/50], Loss: 0.3755743205547333\n",
            "Epoch [45/50], Loss: 0.447213739156723\n",
            "Epoch [46/50], Loss: 0.3586258888244629\n",
            "Epoch [47/50], Loss: 0.3899908661842346\n",
            "Epoch [48/50], Loss: 0.3358018398284912\n",
            "Epoch [49/50], Loss: 0.3819122016429901\n",
            "Epoch [50/50], Loss: 0.4907796084880829\n",
            "Accuracy: 0.9895833333333334, Specificity: 0.9861111111111112, Sensitivity: 0.9930555555555556\n",
            "\n",
            "Fold 6/10\n",
            "Epoch [1/50], Loss: 0.6348122954368591\n",
            "Epoch [2/50], Loss: 0.5831091403961182\n",
            "Epoch [3/50], Loss: 0.60540771484375\n",
            "Epoch [4/50], Loss: 0.5942330360412598\n",
            "Epoch [5/50], Loss: 0.575798511505127\n",
            "Epoch [6/50], Loss: 0.5108601450920105\n",
            "Epoch [7/50], Loss: 0.5444332957267761\n",
            "Epoch [8/50], Loss: 0.49709343910217285\n",
            "Epoch [9/50], Loss: 0.49757272005081177\n",
            "Epoch [10/50], Loss: 0.4815083146095276\n",
            "Epoch [11/50], Loss: 0.566750705242157\n",
            "Epoch [12/50], Loss: 0.4886573553085327\n",
            "Epoch [13/50], Loss: 0.5592833161354065\n",
            "Epoch [14/50], Loss: 0.46863555908203125\n",
            "Epoch [15/50], Loss: 0.47086089849472046\n",
            "Epoch [16/50], Loss: 0.519112229347229\n",
            "Epoch [17/50], Loss: 0.5345006585121155\n",
            "Epoch [18/50], Loss: 0.4759637117385864\n",
            "Epoch [19/50], Loss: 0.36017000675201416\n",
            "Epoch [20/50], Loss: 0.3177025318145752\n",
            "Epoch [21/50], Loss: 0.46630948781967163\n",
            "Epoch [22/50], Loss: 0.4640311002731323\n",
            "Epoch [23/50], Loss: 0.5162934064865112\n",
            "Epoch [24/50], Loss: 0.44957560300827026\n",
            "Epoch [25/50], Loss: 0.48968830704689026\n",
            "Epoch [26/50], Loss: 0.3872092068195343\n",
            "Epoch [27/50], Loss: 0.38892316818237305\n",
            "Epoch [28/50], Loss: 0.3946317434310913\n",
            "Epoch [29/50], Loss: 0.44339895248413086\n",
            "Epoch [30/50], Loss: 0.5558461546897888\n",
            "Epoch [31/50], Loss: 0.32581591606140137\n",
            "Epoch [32/50], Loss: 0.46998292207717896\n",
            "Epoch [33/50], Loss: 0.32285258173942566\n",
            "Epoch [34/50], Loss: 0.3988023102283478\n",
            "Epoch [35/50], Loss: 0.4154953062534332\n",
            "Epoch [36/50], Loss: 0.3933620750904083\n",
            "Epoch [37/50], Loss: 0.4480668008327484\n",
            "Epoch [38/50], Loss: 0.44037488102912903\n",
            "Epoch [39/50], Loss: 0.35896268486976624\n",
            "Epoch [40/50], Loss: 0.4597877860069275\n",
            "Epoch [41/50], Loss: 0.37145450711250305\n",
            "Epoch [42/50], Loss: 0.5017558336257935\n",
            "Epoch [43/50], Loss: 0.3778136968612671\n",
            "Epoch [44/50], Loss: 0.333911269903183\n",
            "Epoch [45/50], Loss: 0.426339328289032\n",
            "Epoch [46/50], Loss: 0.3348950445652008\n",
            "Epoch [47/50], Loss: 0.3915715217590332\n",
            "Epoch [48/50], Loss: 0.4517747461795807\n",
            "Epoch [49/50], Loss: 0.4592159390449524\n",
            "Epoch [50/50], Loss: 0.4239300489425659\n",
            "Accuracy: 0.9930555555555556, Specificity: 0.9930555555555556, Sensitivity: 0.9930555555555556\n",
            "\n",
            "Fold 7/10\n",
            "Epoch [1/50], Loss: 0.6867525577545166\n",
            "Epoch [2/50], Loss: 0.6944956183433533\n",
            "Epoch [3/50], Loss: 0.6404010653495789\n",
            "Epoch [4/50], Loss: 0.6980569958686829\n",
            "Epoch [5/50], Loss: 0.6941278576850891\n",
            "Epoch [6/50], Loss: 0.7051480412483215\n",
            "Epoch [7/50], Loss: 0.6056036353111267\n",
            "Epoch [8/50], Loss: 0.6035714745521545\n",
            "Epoch [9/50], Loss: 0.5630368590354919\n",
            "Epoch [10/50], Loss: 0.6488005518913269\n",
            "Epoch [11/50], Loss: 0.6455404758453369\n",
            "Epoch [12/50], Loss: 0.6084882616996765\n",
            "Epoch [13/50], Loss: 0.6077277064323425\n",
            "Epoch [14/50], Loss: 0.5951902270317078\n",
            "Epoch [15/50], Loss: 0.6264742612838745\n",
            "Epoch [16/50], Loss: 0.589958906173706\n",
            "Epoch [17/50], Loss: 0.650999128818512\n",
            "Epoch [18/50], Loss: 0.5739074945449829\n",
            "Epoch [19/50], Loss: 0.6053809523582458\n",
            "Epoch [20/50], Loss: 0.5992875695228577\n",
            "Epoch [21/50], Loss: 0.5982949137687683\n",
            "Epoch [22/50], Loss: 0.5335190296173096\n",
            "Epoch [23/50], Loss: 0.6656712293624878\n",
            "Epoch [24/50], Loss: 0.6035493016242981\n",
            "Epoch [25/50], Loss: 0.47889864444732666\n",
            "Epoch [26/50], Loss: 0.5234464406967163\n",
            "Epoch [27/50], Loss: 0.4666453003883362\n",
            "Epoch [28/50], Loss: 0.4771086275577545\n",
            "Epoch [29/50], Loss: 0.470295786857605\n",
            "Epoch [30/50], Loss: 0.5675212740898132\n",
            "Epoch [31/50], Loss: 0.5219874978065491\n",
            "Epoch [32/50], Loss: 0.42651498317718506\n",
            "Epoch [33/50], Loss: 0.5082398653030396\n",
            "Epoch [34/50], Loss: 0.6985015273094177\n",
            "Epoch [35/50], Loss: 0.590312123298645\n",
            "Epoch [36/50], Loss: 0.5817025899887085\n",
            "Epoch [37/50], Loss: 0.5926648378372192\n",
            "Epoch [38/50], Loss: 0.48402002453804016\n",
            "Epoch [39/50], Loss: 0.5102590918540955\n",
            "Epoch [40/50], Loss: 0.3664013743400574\n",
            "Epoch [41/50], Loss: 0.4113399088382721\n",
            "Epoch [42/50], Loss: 0.3749805688858032\n",
            "Epoch [43/50], Loss: 0.49177753925323486\n",
            "Epoch [44/50], Loss: 0.5490040183067322\n",
            "Epoch [45/50], Loss: 0.6013956665992737\n",
            "Epoch [46/50], Loss: 0.3347305357456207\n",
            "Epoch [47/50], Loss: 0.5209667682647705\n",
            "Epoch [48/50], Loss: 0.6631262898445129\n",
            "Epoch [49/50], Loss: 0.39457011222839355\n",
            "Epoch [50/50], Loss: 0.47661808133125305\n",
            "Accuracy: 0.9930555555555556, Specificity: 0.9861111111111112, Sensitivity: 1.0\n",
            "\n",
            "Fold 8/10\n",
            "Epoch [1/50], Loss: 0.6092844009399414\n",
            "Epoch [2/50], Loss: 0.5013983249664307\n",
            "Epoch [3/50], Loss: 0.584017813205719\n",
            "Epoch [4/50], Loss: 0.4980306625366211\n",
            "Epoch [5/50], Loss: 0.5465835928916931\n",
            "Epoch [6/50], Loss: 0.428385853767395\n",
            "Epoch [7/50], Loss: 0.5257536172866821\n",
            "Epoch [8/50], Loss: 0.49976009130477905\n",
            "Epoch [9/50], Loss: 0.5686006546020508\n",
            "Epoch [10/50], Loss: 0.42269986867904663\n",
            "Epoch [11/50], Loss: 0.4288973808288574\n",
            "Epoch [12/50], Loss: 0.30451321601867676\n",
            "Epoch [13/50], Loss: 0.37949758768081665\n",
            "Epoch [14/50], Loss: 0.3957675099372864\n",
            "Epoch [15/50], Loss: 0.39873677492141724\n",
            "Epoch [16/50], Loss: 0.5757869482040405\n",
            "Epoch [17/50], Loss: 0.3611682057380676\n",
            "Epoch [18/50], Loss: 0.37486928701400757\n",
            "Epoch [19/50], Loss: 0.25200948119163513\n",
            "Epoch [20/50], Loss: 0.3773289918899536\n",
            "Epoch [21/50], Loss: 0.4318651854991913\n",
            "Epoch [22/50], Loss: 0.4335860013961792\n",
            "Epoch [23/50], Loss: 0.3281382918357849\n",
            "Epoch [24/50], Loss: 0.32634299993515015\n",
            "Epoch [25/50], Loss: 0.32816535234451294\n",
            "Epoch [26/50], Loss: 0.2929646968841553\n",
            "Epoch [27/50], Loss: 0.4356954097747803\n",
            "Epoch [28/50], Loss: 0.41349899768829346\n",
            "Epoch [29/50], Loss: 0.3936766982078552\n",
            "Epoch [30/50], Loss: 0.3260393738746643\n",
            "Epoch [31/50], Loss: 0.33808469772338867\n",
            "Epoch [32/50], Loss: 0.24360252916812897\n",
            "Epoch [33/50], Loss: 0.5158110857009888\n",
            "Epoch [34/50], Loss: 0.30423635244369507\n",
            "Epoch [35/50], Loss: 0.4366777539253235\n",
            "Epoch [36/50], Loss: 0.271135538816452\n",
            "Epoch [37/50], Loss: 0.33826959133148193\n",
            "Epoch [38/50], Loss: 0.2653942406177521\n",
            "Epoch [39/50], Loss: 0.28971144556999207\n",
            "Epoch [40/50], Loss: 0.3912176489830017\n",
            "Epoch [41/50], Loss: 0.26984983682632446\n",
            "Epoch [42/50], Loss: 0.25935304164886475\n",
            "Epoch [43/50], Loss: 0.38832852244377136\n",
            "Epoch [44/50], Loss: 0.3370661735534668\n",
            "Epoch [45/50], Loss: 0.321882426738739\n",
            "Epoch [46/50], Loss: 0.2133362889289856\n",
            "Epoch [47/50], Loss: 0.42204949259757996\n",
            "Epoch [48/50], Loss: 0.23394793272018433\n",
            "Epoch [49/50], Loss: 0.21713465452194214\n",
            "Epoch [50/50], Loss: 0.3693554699420929\n",
            "Accuracy: 0.9965277777777778, Specificity: 0.9930555555555556, Sensitivity: 1.0\n",
            "\n",
            "Fold 9/10\n",
            "Epoch [1/50], Loss: 0.6393431425094604\n",
            "Epoch [2/50], Loss: 0.6200552582740784\n",
            "Epoch [3/50], Loss: 0.6896321177482605\n",
            "Epoch [4/50], Loss: 0.6688304543495178\n",
            "Epoch [5/50], Loss: 0.6438573002815247\n",
            "Epoch [6/50], Loss: 0.6458547711372375\n",
            "Epoch [7/50], Loss: 0.6217348575592041\n",
            "Epoch [8/50], Loss: 0.6331233382225037\n",
            "Epoch [9/50], Loss: 0.5703051090240479\n",
            "Epoch [10/50], Loss: 0.638432502746582\n",
            "Epoch [11/50], Loss: 0.655078649520874\n",
            "Epoch [12/50], Loss: 0.5244337916374207\n",
            "Epoch [13/50], Loss: 0.6090656518936157\n",
            "Epoch [14/50], Loss: 0.5903825759887695\n",
            "Epoch [15/50], Loss: 0.6303240060806274\n",
            "Epoch [16/50], Loss: 0.6075458526611328\n",
            "Epoch [17/50], Loss: 0.5648657083511353\n",
            "Epoch [18/50], Loss: 0.6428293585777283\n",
            "Epoch [19/50], Loss: 0.5636423230171204\n",
            "Epoch [20/50], Loss: 0.5730258226394653\n",
            "Epoch [21/50], Loss: 0.7058292031288147\n",
            "Epoch [22/50], Loss: 0.592705249786377\n",
            "Epoch [23/50], Loss: 0.579868495464325\n",
            "Epoch [24/50], Loss: 0.5470066070556641\n",
            "Epoch [25/50], Loss: 0.5396260619163513\n",
            "Epoch [26/50], Loss: 0.6027069091796875\n",
            "Epoch [27/50], Loss: 0.3891223669052124\n",
            "Epoch [28/50], Loss: 0.545405924320221\n",
            "Epoch [29/50], Loss: 0.5633397698402405\n",
            "Epoch [30/50], Loss: 0.5550230145454407\n",
            "Epoch [31/50], Loss: 0.7407585978507996\n",
            "Epoch [32/50], Loss: 0.48092785477638245\n",
            "Epoch [33/50], Loss: 0.5102130770683289\n",
            "Epoch [34/50], Loss: 0.5527609586715698\n",
            "Epoch [35/50], Loss: 0.4987720847129822\n",
            "Epoch [36/50], Loss: 0.5400310158729553\n",
            "Epoch [37/50], Loss: 0.5833340883255005\n",
            "Epoch [38/50], Loss: 0.5578581690788269\n",
            "Epoch [39/50], Loss: 0.5412583947181702\n",
            "Epoch [40/50], Loss: 0.554143488407135\n",
            "Epoch [41/50], Loss: 0.49014943838119507\n",
            "Epoch [42/50], Loss: 0.5953795909881592\n",
            "Epoch [43/50], Loss: 0.44530051946640015\n",
            "Epoch [44/50], Loss: 0.5492233633995056\n",
            "Epoch [45/50], Loss: 0.4470774829387665\n",
            "Epoch [46/50], Loss: 0.47225359082221985\n",
            "Epoch [47/50], Loss: 0.43102145195007324\n",
            "Epoch [48/50], Loss: 0.4939824044704437\n",
            "Epoch [49/50], Loss: 0.5494305491447449\n",
            "Epoch [50/50], Loss: 0.4478629231452942\n",
            "Accuracy: 0.9930555555555556, Specificity: 0.9861111111111112, Sensitivity: 1.0\n",
            "\n",
            "Fold 10/10\n",
            "Epoch [1/50], Loss: 0.6278867721557617\n",
            "Epoch [2/50], Loss: 0.5911892056465149\n",
            "Epoch [3/50], Loss: 0.5228416919708252\n",
            "Epoch [4/50], Loss: 0.5426080822944641\n",
            "Epoch [5/50], Loss: 4.260279655456543\n",
            "Epoch [6/50], Loss: 0.3409148156642914\n",
            "Epoch [7/50], Loss: 0.5111450552940369\n",
            "Epoch [8/50], Loss: 0.37428510189056396\n",
            "Epoch [9/50], Loss: 0.9902420043945312\n",
            "Epoch [10/50], Loss: 0.5451775193214417\n",
            "Epoch [11/50], Loss: 0.5002462863922119\n",
            "Epoch [12/50], Loss: 0.4976140558719635\n",
            "Epoch [13/50], Loss: 0.4394768476486206\n",
            "Epoch [14/50], Loss: 0.43749934434890747\n",
            "Epoch [15/50], Loss: 0.6218783259391785\n",
            "Epoch [16/50], Loss: 0.47967231273651123\n",
            "Epoch [17/50], Loss: 0.5802680253982544\n",
            "Epoch [18/50], Loss: 0.4553385376930237\n",
            "Epoch [19/50], Loss: 0.5404569506645203\n",
            "Epoch [20/50], Loss: 0.3323541581630707\n",
            "Epoch [21/50], Loss: 0.42919638752937317\n",
            "Epoch [22/50], Loss: 0.3951783776283264\n",
            "Epoch [23/50], Loss: 0.39202213287353516\n",
            "Epoch [24/50], Loss: 0.41145649552345276\n",
            "Epoch [25/50], Loss: 0.5324695706367493\n",
            "Epoch [26/50], Loss: 0.4964669644832611\n",
            "Epoch [27/50], Loss: 0.4317533075809479\n",
            "Epoch [28/50], Loss: 0.4874843955039978\n",
            "Epoch [29/50], Loss: 0.4557247757911682\n",
            "Epoch [30/50], Loss: 0.33786875009536743\n",
            "Epoch [31/50], Loss: 0.4484829604625702\n",
            "Epoch [32/50], Loss: 0.49823197722435\n",
            "Epoch [33/50], Loss: 0.3648432493209839\n",
            "Epoch [34/50], Loss: 0.3797411620616913\n",
            "Epoch [35/50], Loss: 0.4364633560180664\n",
            "Epoch [36/50], Loss: 0.4962385594844818\n",
            "Epoch [37/50], Loss: 0.42754924297332764\n",
            "Epoch [38/50], Loss: 0.43763136863708496\n",
            "Epoch [39/50], Loss: 0.5134010910987854\n",
            "Epoch [40/50], Loss: 0.34473562240600586\n",
            "Epoch [41/50], Loss: 0.41094255447387695\n",
            "Epoch [42/50], Loss: 0.4743154048919678\n",
            "Epoch [43/50], Loss: 0.5750836133956909\n",
            "Epoch [44/50], Loss: 0.32759127020835876\n",
            "Epoch [45/50], Loss: 0.3768824338912964\n",
            "Epoch [46/50], Loss: 0.41354048252105713\n",
            "Epoch [47/50], Loss: 0.3099544048309326\n",
            "Epoch [48/50], Loss: 0.301726371049881\n",
            "Epoch [49/50], Loss: 0.41080957651138306\n",
            "Epoch [50/50], Loss: 0.4094991683959961\n",
            "Accuracy: 1.0, Specificity: 1.0, Sensitivity: 1.0\n",
            "\n",
            "Average Accuracy: 0.9927083333333334\n",
            "Average Specificity: 0.9895833333333334\n",
            "Average Sensitivity: 0.9958333333333333\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the evaluation metrics\n",
        "def calculate_metrics(conf_matrix):\n",
        "    true_positive = conf_matrix[1, 1]\n",
        "    true_negative = conf_matrix[0, 0]\n",
        "    false_positive = conf_matrix[0, 1]\n",
        "    false_negative = conf_matrix[1, 0]\n",
        "\n",
        "    accuracy = (true_positive + true_negative) / np.sum(conf_matrix)\n",
        "    specificity = true_negative / (true_negative + false_positive)\n",
        "    sensitivity = true_positive / (true_positive + false_negative)\n",
        "\n",
        "    return accuracy, specificity, sensitivity\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "num_folds = 10\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "sincnet_accuracies = []\n",
        "sincnet_specificities = []\n",
        "sincnet_sensitivities = []\n",
        "sincnet_loss_history = [[0 for x in range(50)] for y in range(10)]\n",
        "\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(data, labels)):\n",
        "    print(f\"Fold {fold+1}/{num_folds}\")\n",
        "\n",
        "    # Create data and labels subsets for this fold\n",
        "    train_data, test_data = data[train_idx], data[test_idx]\n",
        "    train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Convert data and labels to PyTorch tensors\n",
        "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "    # Create DataLoader for training\n",
        "    train_dataset = TensorDataset(train_data, train_labels)\n",
        "    batch_size = 32\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Create the model instance\n",
        "    model = PDSincNet()\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Assuming it's a classification task\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 50\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_data, batch_labels in train_dataloader:\n",
        "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_data)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sincnet_loss_history[fold].append(loss.item())\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data = test_data.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        predictions = model(test_data)\n",
        "        _, predicted_labels = torch.max(predictions, 1)\n",
        "        conf_matrix = confusion_matrix(test_labels.cpu(), predicted_labels.cpu())\n",
        "        accuracy, specificity, sensitivity = calculate_metrics(conf_matrix)\n",
        "        sincnet_accuracies.append(accuracy)\n",
        "        sincnet_specificities.append(specificity)\n",
        "        sincnet_sensitivities.append(sensitivity)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}, Specificity: {specificity}, Sensitivity: {sensitivity}\\n\")\n",
        "\n",
        "# Calculate average metrics over all folds\n",
        "avg_accuracy = np.mean(sincnet_accuracies)\n",
        "avg_specificity = np.mean(sincnet_specificities)\n",
        "avg_sensitivity = np.mean(sincnet_sensitivities)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}\")\n",
        "print(f\"Average Specificity: {avg_specificity}\")\n",
        "print(f\"Average Sensitivity: {avg_sensitivity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzC1lHGfINzC"
      },
      "outputs": [],
      "source": [
        "sincnet_results = {\n",
        "        'accuracies': sincnet_accuracies,\n",
        "        'sensitivities': sincnet_sensitivities,\n",
        "        'specificities': sincnet_specificities\n",
        "    }\n",
        "\n",
        "np.save(base_path + \"sincnet_results.npy\", sincnet_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCb4fZDw1Zbu"
      },
      "outputs": [],
      "source": [
        "np.save(base_path + \"sincnet_loss.npy\", sincnet_loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3niusNBFwHe"
      },
      "source": [
        "#Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khh6fFP1Hs72",
        "outputId": "61a53c3b-f299-4bd7-b0f2-d7346c2629ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4100"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_history2 = np.load(base_path + \"sincnet_loss.npy\")\n",
        "loss_history1 = np.load(base_path + \"cnn_loss.npy\")\n",
        "len(loss_history2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm7FPIx4jBEY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a list of epoch numbers (assuming epoch numbers start from 1)\n",
        "epochs = np.arange(1, 51)\n",
        "\n",
        "# Create the line plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size if needed\n",
        "plt.plot(epochs, loss_history1, label='Model 1', marker='o', linestyle='-')\n",
        "plt.plot(epochs, loss_history2, label='Model 2', marker='x', linestyle='-')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXGhvXF6FvUY"
      },
      "outputs": [],
      "source": [
        "loaded_sincnet_results = np.load(base_path + \"sincnet_results.npy\", allow_pickle=True).item()\n",
        "loaded_cnn_results = np.load(base_path + \"cnn_results.npy\", allow_pickle=True).item()\n",
        "loaded_lstm_results = np.load(base_path + \"lstm_results.npy\", allow_pickle=True).item()\n",
        "loaded_svm_results = np.load(base_path + \"svm_results.npy\", allow_pickle=True).item()\n",
        "\n",
        "sincnet_accuracies = loaded_sincnet_results['accuracies']\n",
        "sincnet_sensitivities = loaded_sincnet_results['sensitivities']\n",
        "sincnet_specificities = loaded_sincnet_results['specificities']\n",
        "\n",
        "cnn_accuracies = loaded_cnn_results['accuracies']\n",
        "cnn_sensitivities = loaded_cnn_results['sensitivities']\n",
        "cnn_specificities = loaded_cnn_results['specificities']\n",
        "\n",
        "lstm_accuracies = loaded_lstm_results['accuracies']\n",
        "lstm_sensitivities = loaded_lstm_results['sensitivities']\n",
        "lstm_specificities = loaded_lstm_results['specificities']\n",
        "\n",
        "svm_accuracies = loaded_svm_results['accuracies']\n",
        "svm_sensitivities = loaded_svm_results['sensitivities']\n",
        "svm_specificities = loaded_svm_results['specificities']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUp7UbMCFTgM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_plot(ylabel , title, sincnet_result, cnn_result, lstm_result, svm_result):\n",
        "\n",
        "  fold_numbers = range(1,11)\n",
        "  bar_width = 0.15\n",
        "  fig, ax = plt.subplots(figsize=(10, 6))\n",
        "  x = np.arange(len(fold_numbers))\n",
        "\n",
        "  ax.bar(x - 3 * bar_width / 2 , sincnet_result, width=bar_width , label='SincNet', align='center')\n",
        "  ax.bar(x - bar_width / 2 , cnn_result, width=bar_width, label='CNN', align='center')\n",
        "  ax.bar(x  + bar_width / 2, lstm_result, width=bar_width, label='LSTM', align='center')\n",
        "  ax.bar(x + 3 * bar_width  / 2, svm_result, width=bar_width, label='SVM', align='center')\n",
        "\n",
        "  # Customize the plot\n",
        "  ax.set_xlabel('Fold Number')\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_title(title)\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(fold_numbers)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
        "            fancybox=True, shadow=True, ncol=5)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "fUTaAii9M1es",
        "outputId": "879f16c1-696c-43fe-d8c3-8a701b741cac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_plot(\"Accuracy\" , 'Model Accuracies in Each Fold' , sincnet_accuracies, cnn_accuracies, lstm_accuracies, svm_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "PenL6BZ5NPel",
        "outputId": "23075698-fb68-4628-a8f9-dda1e00d19e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_plot(\"Sensitivity\" , 'Model sensitivities in Each Fold' , sincnet_sensitivities, cnn_sensitivities, lstm_sensitivities, svm_sensitivities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "MgkdPswpNawk",
        "outputId": "22f505f3-63d8-44e5-e602-7f12b34904c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_plot(\"Specificity\" , 'Model specificities in Each Fold' , sincnet_specificities, cnn_specificities, lstm_specificities, svm_specificities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrlE69STnpBl"
      },
      "source": [
        "#SincNet Implementation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvsJxED9KEKv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SincConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, sample_rate):\n",
        "        super(SincConv, self).__init__()\n",
        "\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_freq = 50.0\n",
        "        self.min_band = 50.0\n",
        "        self.kernel_size = kernel_size\n",
        "        self.param = nn.Parameter(torch.Tensor(out_channels, in_channels, 1))\n",
        "\n",
        "        # Initialize the weights\n",
        "        self.param.data.uniform_(-0.01, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        filters = self.param\n",
        "\n",
        "        # Compute bandpass filters\n",
        "        low = self.min_freq / self.sample_rate\n",
        "        high = (self.min_freq + 2.0 * self.min_band) / self.sample_rate\n",
        "        t_right = (torch.arange(1, self.kernel_size + 1, dtype=torch.float32) - (self.kernel_size + 1) / 2.0) / self.sample_rate\n",
        "        bandpass = 2.0 * high * torch.sinc(2.0 * high * t_right) - 2.0 * low * torch.sinc(2.0 * low * t_right)\n",
        "\n",
        "        filters = filters * bandpass.view(1, 1, -1)\n",
        "\n",
        "        # Apply the filters\n",
        "        x = F.conv1d(x, filters)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IN23XfLfB-t"
      },
      "outputs": [],
      "source": [
        "class PDCNNWithSinc(nn.Module):\n",
        "    def __init__(self, sample_rate):\n",
        "        super(PDCNNWithSinc, self).__init__()\n",
        "\n",
        "        # SincNet layer\n",
        "        self.sinc_conv = SincConv(in_channels=1, out_channels=41, kernel_size=101, sample_rate=sample_rate)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=41, out_channels=5, kernel_size=20, stride=1)\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels=5, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10, kernel_size=10, stride=1)\n",
        "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=15, kernel_size=5, stride=1)\n",
        "        self.maxpool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=19530, out_features=20)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=20, out_features=10)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(in_features=10, out_features=2)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply SincNet layer\n",
        "        x =self.maxpool1(torch.relu(self.sinc_conv(x)))\n",
        "\n",
        "        x = self.maxpool1(torch.relu(self.conv1(x)))\n",
        "        x = self.maxpool2(torch.relu(self.conv2(x)))\n",
        "        x = self.maxpool3(torch.relu(self.conv3(x)))\n",
        "        x = self.maxpool4(torch.relu(self.conv4(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
        "        x = self.dropout2(torch.relu(self.fc2(x)))\n",
        "        x = self.dropout3(self.fc3(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqYHIR0Kcdg8",
        "outputId": "b14dcd15-6c4c-4504-9762-b6a71a3185c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the evaluation metrics\n",
        "def calculate_metrics(conf_matrix):\n",
        "    true_positive = conf_matrix[1, 1]\n",
        "    true_negative = conf_matrix[0, 0]\n",
        "    false_positive = conf_matrix[0, 1]\n",
        "    false_negative = conf_matrix[1, 0]\n",
        "\n",
        "    accuracy = (true_positive + true_negative) / np.sum(conf_matrix)\n",
        "    specificity = true_negative / (true_negative + false_positive)\n",
        "    sensitivity = true_positive / (true_positive + false_negative)\n",
        "\n",
        "    return accuracy, specificity, sensitivity\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "num_folds = 10\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "accuracies = []\n",
        "specificities = []\n",
        "sensitivities = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(data, labels)):\n",
        "    print(f\"Fold {fold+1}/{num_folds}\")\n",
        "\n",
        "    # Create data and labels subsets for this fold\n",
        "    train_data, test_data = data[train_idx], data[test_idx]\n",
        "    train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Convert data and labels to PyTorch tensors\n",
        "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "    # Create DataLoader for training\n",
        "    train_dataset = TensorDataset(train_data, train_labels)\n",
        "    batch_size = 32\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Create the model instance (PDCNN)\n",
        "    model = PDCNNWithSinc(sample_rate=512.0)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Assuming it's a classification task\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 50\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_data, batch_labels in train_dataloader:\n",
        "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_data)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data = test_data.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        predictions = model(test_data)\n",
        "        _, predicted_labels = torch.max(predictions, 1)\n",
        "        conf_matrix = confusion_matrix(test_labels.cpu(), predicted_labels.cpu())\n",
        "        accuracy, specificity, sensitivity = calculate_metrics(conf_matrix)\n",
        "        accuracies.append(accuracy)\n",
        "        specificities.append(specificity)\n",
        "        sensitivities.append(sensitivity)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}, Specificity: {specificity}, Sensitivity: {sensitivity}\\n\")\n",
        "\n",
        "# Calculate average metrics over all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_specificity = np.mean(specificities)\n",
        "avg_sensitivity = np.mean(sensitivities)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}\")\n",
        "print(f\"Average Specificity: {avg_specificity}\")\n",
        "print(f\"Average Sensitivity: {avg_sensitivity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_YaLJV7o0f0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ka7pUKRNQhEh",
        "jrlE69STnpBl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}